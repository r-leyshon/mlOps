{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deployment Considerations\n",
    "\n",
    "A strong point to consider deployment from the early stages of scoping a project is made. Pressing on with the development in earnest prior to understanding the architecture tha app will be hosted on can cause all sorts of problems that ultimately cost more development time. \n",
    "\n",
    "Once a Data Scientist presents a trained model for hosting, here are some effective steps to consider:\n",
    "\n",
    "1. **Compatability with infrastructure.** Will it run on the target infrastructure?\n",
    "2. **Reproducibility.**\n",
    "    - metadata store\n",
    "    - data versioning\n",
    "3. **Validation.**\n",
    "    - data profile to store expected value references for comparison\n",
    "4. **Logging.**\n",
    "    - Monitoring of performance over time.\n",
    "    - logging at 3 key stages, input data, system errors or warnings, predicted values.\n",
    "5. **Maintenance.**\n",
    "    - Bugfixes, feature requests etc will need to be handled.\n",
    "    - How confident will you be in adjusting the codebase may be related to the\n",
    "    comprehensive test suite included with the code.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profiling\n",
    "\n",
    "Automated data analytics. Used to produce high level summary stats, refered to as **data\n",
    "profiles** or **expectations**. This can be used to provide useful error messages to\n",
    "users who provide erroneous inputs to the model or to indicate when enough data drift\n",
    "has accumulated to suggest a need to retrain the model. \n",
    "\n",
    "Data profiles should be stored within the **metadata store**.\n",
    "\n",
    "The widely used [Great Expectations](https://github.com/great-expectations/great_expectations) package in Python can be used for these purposes.\n",
    "\n",
    "![Great Expectations Logo](https://github.com/great-expectations/great_expectations/blob/develop/docs/docusaurus/static/img/gx-mark-160.png?raw=true)\n",
    "\n",
    "\n",
    "## Data Version Control\n",
    "\n",
    "It's important to be able to reproduce the model by recording which version of the data the model was trained upon. The data itself should be stored wihtin the data store, however in the **metadata store** we can record a pointer to the data version with a verification fingerprint. If a single record in the dataset has changed, the fingerprint will not match. \n",
    "\n",
    "The model metadata should also record info to be able to reproduce the train test split used during model training.\n",
    "\n",
    "Data versioning is often done with [Data Version Control](https://dvc.org/).\n",
    "\n",
    "![DVC Logo](https://camo.githubusercontent.com/39f29e4d02d44888b656a15b1b51c14db4a139fb12da62b3c4e150b9bffa3373/68747470733a2f2f6476632e6f72672f696d672f6c6f676f2d6769746875622d726561646d652e706e67)\n",
    "\n",
    "## Feature Stores\n",
    "\n",
    "Record prepared data in **dual databases**, 1 part being optimised for bulk record\n",
    "retrieval during training phase and the other part optimised for single record retrieval\n",
    "during prediction.\n",
    "\n",
    "Feature stores allow you to use features multiple times across several models. They also\n",
    "reduce **train-serve skew**, where your model performs worse in production than at\n",
    "training.\n",
    "\n",
    "Such skew can be experienced by training your model on clean data, when during\n",
    "production the model will receive mostly unclean / differently formatted data. For\n",
    "example, training a spam filter on extracted Email text when the user will mostly be\n",
    "passing HTML format.\n",
    "\n",
    "***\n",
    "\n",
    "Model Build Pipelines\n",
    "\n",
    "A distinction is made between model pipeline & model build pipeline.\n",
    "\n",
    "**Model Pipeline** considers the standard engineering to prediction workflow covered by \n",
    "say a scikit-learn pipeline. Compare with model build below.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Pipeline\n",
    "```{mermaid}\n",
    "flowchart LR\n",
    "    input([\"Raw Data\"])\n",
    "    subgraph preprocessing\n",
    "    eng[\"Engineering\"]\n",
    "    feat[\"Feature Extraction\"]\n",
    "    end\n",
    "    subgraph prediction\n",
    "    pred[\"Classification\"]\n",
    "    end\n",
    "    lab([\"Label\"])\n",
    "    input --> eng --> feat --> pred --> lab\n",
    "```\n",
    "\n",
    "### Model **Build** Pipeline\n",
    "\n",
    "```{mermaid}\n",
    "flowchart LR\n",
    "    mod[\"Model Pipeline\"]\n",
    "    dat[\"Training Data\"]\n",
    "    train[\"Model Training\"]\n",
    "    write[\"Save Model\"]\n",
    "    mod --> train\n",
    "    dat --> train --> write\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
